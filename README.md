# Android Google Play API Demos

<b>ActivityRecognitionDemo</b> uses the Activity Recognition API provide in the GooglePlay APIs.  This example show the mostl likel activity (and speech), plus any activities that "it" thinks are at least 50% likely.  

<b>AcitivtyRecognition</b> is google's example code from https://github.com/googlesamples/android-play-location/tree/master/ActivityRecognition and will should likely be removed from this repo

<b>GoogleLoginDemo</b> is a example of how to use the new login APIs.  This example is so very basic that is doesn't do anything other then login.  As note, if you run this example of two devices with the same user and login on one device, then start the activity on the second device, it will already be logined.

<b>LocationAwareDemo</b> shows how to use the APIs to do location better then standard GPS demos.  plus will show the likely address of your location.

<b>FaceTrackerDemo</b> uses the GooglePlay vision APIs to track see if the user has the eyes open and is similing.  It uses text to speech to tell you if they are open/smiling or not.  See https://github.com/googlesamples/android-vision 


<b>FaceTrackerDemo</b> uses the GooglePlay vision APIs to track see if the user has the eyes open and is similing.  Uses the graphic overlay to put green cirles (eye open) or red x for close.  Green box for smiling, red x not smiling over the mouth.
See https://github.com/googlesamples/android-vision 

<b>BarocdeReader</b> use the googlePlay vision APIs to find a barcode and ask if you want to search amazon or open the web page.  This a very simple example.  

These are example code for University of Wyoming, Cosc 4730 Mobile Programming course and Cosc 4735 Advanced Mobile Programming course.
All examples are for Android.

